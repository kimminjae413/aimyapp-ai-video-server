// services/hybridImageService.ts - ìµœì¢… ì™„ì„± ë²„ì „ (ì§„ì§œ gpt-image-1 + ê¸°ì¡´ ê¸°ëŠ¥ í†µí•©)
import { changeClothingOnly, changeFaceInImage } from './geminiService';
import { PNGConverter } from '../utils/pngConverter';
import type { ImageFile } from '../types';

// ë§¨ ìœ„ì— ìˆ˜ì •
console.log('ğŸš€ HYBRID SERVICE VERSION: 4.0 - gpt-image-1 + Gemini 2.5-Flash');
console.log('ğŸ“… BUILD: 2025-09-12-18:00 - CACHE BUSTED');

/**
 * ğŸ†• ì´ë¯¸ì§€ ì°¨ì› ì¶”ì¶œ í•¨ìˆ˜
 */
const getImageDimensions = (imageFile: ImageFile): Promise<{width: number, height: number}> => {
    return new Promise((resolve) => {
        const img = new Image();
        img.onload = () => {
            resolve({ width: img.width, height: img.height });
        };
        img.src = imageFile.url;
    });
};

/**
 * ğŸ“ gpt-image-1 ì „ìš© ë¦¬ì‚¬ì´ì¦ˆ (ê¸°ì¡´ ë°©ì‹ ê°œì„ )
 */
const resizeImageForGPTImage1 = (originalImage: ImageFile): Promise<ImageFile> => {
    return new Promise((resolve) => {
        const img = new Image();
        img.onload = () => {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d')!;
            
            // gpt-image-1 ìµœì í™”: ë” í° í¬ê¸° í—ˆìš©í•˜ì§€ë§Œ 4MB ì œí•œ ê³ ë ¤
            const maxSize = 1536; // ê¸°ì¡´ 1024ì—ì„œ ì¦ê°€
            const ratio = Math.min(maxSize / img.width, maxSize / img.height);
            
            const newWidth = Math.round(img.width * ratio);
            const newHeight = Math.round(img.height * ratio);
            
            // ìµœì†Œ í¬ê¸° ë³´ì¥ (ì–¼êµ´ ì¸ì‹ì„ ìœ„í•´)
            const minSize = 768;
            let finalWidth = newWidth;
            let finalHeight = newHeight;
            
            if (finalWidth < minSize && finalHeight < minSize) {
                const upscaleRatio = Math.max(minSize / finalWidth, minSize / finalHeight);
                finalWidth = Math.round(finalWidth * upscaleRatio);
                finalHeight = Math.round(finalHeight * upscaleRatio);
            }
            
            canvas.width = finalWidth;
            canvas.height = finalHeight;
            
            // ê³ í’ˆì§ˆ ë Œë”ë§ (gpt-image-1ìš©)
            ctx.imageSmoothingEnabled = true;
            ctx.imageSmoothingQuality = 'high';
            ctx.drawImage(img, 0, 0, finalWidth, finalHeight);
            
            const resizedDataUrl = canvas.toDataURL('image/jpeg', 0.9); // ê³ í’ˆì§ˆ ìœ ì§€
            const resizedBase64 = resizedDataUrl.split(',')[1];
            
            console.log('gpt-image-1ìš© ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ:', {
                original: `${img.width}x${img.height}`,
                resized: `${finalWidth}x${finalHeight}`,
                ratio: (finalWidth/finalHeight).toFixed(2),
                originalSize: Math.round(originalImage.base64.length / 1024) + 'KB',
                resizedSize: Math.round(resizedBase64.length / 1024) + 'KB'
            });
            
            resolve({
                base64: resizedBase64,
                mimeType: 'image/jpeg',
                url: resizedDataUrl
            });
        };
        img.src = originalImage.url;
    });
};

/**
 * ğŸ†• ì¢…íš¡ë¹„ ë³´ì • í•¨ìˆ˜ - gpt-image-1 ê²°ê³¼ë¬¼ì„ ì›ë³¸ ë¹„ìœ¨ë¡œ ë³µì›
 */
const correctAspectRatio = (
    resultImageBase64: string, 
    originalWidth: number, 
    originalHeight: number
): Promise<string> => {
    return new Promise((resolve, reject) => {
        const img = new Image();
        img.onload = () => {
            try {
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d')!;
                
                // ì›ë³¸ ì¢…íš¡ë¹„ ê³„ì‚°
                const originalRatio = originalWidth / originalHeight;
                const currentRatio = img.width / img.height;
                
                console.log('ì¢…íš¡ë¹„ ë¶„ì„:', {
                    ì›ë³¸: `${originalWidth}x${originalHeight} (${originalRatio.toFixed(2)})`,
                    gptê²°ê³¼: `${img.width}x${img.height} (${currentRatio.toFixed(2)})`,
                    ë³´ì •í•„ìš”: Math.abs(originalRatio - currentRatio) > 0.15
                });
                
                // ì¢…íš¡ë¹„ê°€ í¬ê²Œ ë‹¤ë¥´ë©´ ë³´ì •, ë¹„ìŠ·í•˜ë©´ ê·¸ëŒ€ë¡œ
                if (Math.abs(originalRatio - currentRatio) > 0.15) {
                    // ì›ë³¸ ë¹„ìœ¨ë¡œ ë³´ì •
                    let targetWidth, targetHeight;
                    
                    if (originalRatio > 1) {
                        // ê°€ë¡œê°€ ë” ê¸´ ê²½ìš°
                        targetWidth = Math.max(img.width, img.height);
                        targetHeight = Math.round(targetWidth / originalRatio);
                    } else {
                        // ì„¸ë¡œê°€ ë” ê¸´ ê²½ìš° (í˜„ì¬ ì¼€ì´ìŠ¤)
                        targetHeight = Math.max(img.width, img.height);
                        targetWidth = Math.round(targetHeight * originalRatio);
                    }
                    
                    canvas.width = targetWidth;
                    canvas.height = targetHeight;
                    
                    console.log('ğŸ”§ ì¢…íš¡ë¹„ ë³´ì • ì‹¤í–‰:', `${targetWidth}x${targetHeight}`);
                } else {
                    // ë¹„ìœ¨ì´ ë¹„ìŠ·í•˜ë©´ ì›ë³¸ í¬ê¸° ìœ ì§€
                    canvas.width = img.width;
                    canvas.height = img.height;
                    
                    console.log('âœ… ì¢…íš¡ë¹„ ë³´ì • ë¶ˆí•„ìš” - ì›ë³¸ ìœ ì§€');
                }
                
                // ê³ í’ˆì§ˆ ë Œë”ë§
                ctx.imageSmoothingEnabled = true;
                ctx.imageSmoothingQuality = 'high';
                ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
                
                const correctedDataUrl = canvas.toDataURL('image/png', 1.0);
                const correctedBase64 = correctedDataUrl.split(',')[1];
                
                resolve(correctedBase64);
            } catch (error) {
                reject(error);
            }
        };
        
        img.onerror = () => reject(new Error('ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨'));
        img.src = `data:image/png;base64,${resultImageBase64}`;
    });
};

/**
 * ğŸ”¥ ì§„ì§œ gpt-image-1 ë°©ì‹ ì–¼êµ´ ë³€í™˜ (ì™„ì „ í†µí•©)
 */
const transformFaceWithGPTImage1 = async (
    originalImage: ImageFile,
    facePrompt: string
): Promise<ImageFile | null> => {
    try {
        console.log('ğŸ¯ ì§„ì§œ gpt-image-1 ë³€í™˜ ì‹œì‘...');
        
        // 1. ì›ë³¸ ì´ë¯¸ì§€ ì°¨ì› ì¶”ì¶œ (ì¢…íš¡ë¹„ ë³´ì •ìš©)
        const originalDimensions = await getImageDimensions(originalImage);
        console.log('ì›ë³¸ ì´ë¯¸ì§€ ì°¨ì›:', originalDimensions);
        
        // 2. ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (gpt-image-1 ìµœì í™”)
        const resizedImage = await resizeImageForGPTImage1(originalImage);
        
        // 3. PNG í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (gpt-image-1 í˜¸í™˜ì„±)
        console.log('gpt-image-1ìš© PNG ë³€í™˜ ì¤‘...');
        const pngBase64 = await PNGConverter.convertToPNGForOpenAI(resizedImage.base64);
        
        // 4. gpt-image-1 ì „ìš© í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ ìµœì í™” ìœ ì§€)
        let optimizedPrompt = `
FACE TRANSFORMATION PRIORITY:
${facePrompt}

EXECUTE:
- Replace ALL facial features completely
- Change face shape, eyes, nose, mouth, skin texture
- Make transformation dramatic and clearly visible
- Create completely different person as requested

SECONDARY:
- Maintain similar hairstyle if possible
- Keep pose and background when feasible

TECHNICAL:
- Generate photorealistic skin texture
- Ensure bold, visible changes
- Focus on complete facial reconstruction

Face transformation is PRIMARY GOAL.
        `.trim();

        // í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        if (optimizedPrompt.length > 1000) {
            optimizedPrompt = optimizedPrompt.substring(0, 997) + '...';
            console.log('Prompt truncated to 1000 characters');
        }

        console.log('Final prompt length:', optimizedPrompt.length, 'characters');
        console.log('ğŸ§  gpt-image-1 API í˜¸ì¶œ (GPT-4V ë¶„ì„ + DALL-E-3 ì¬êµ¬ì„±)...');

        // 5. ì§„ì§œ gpt-image-1 API í˜¸ì¶œ
        const response = await fetch('/.netlify/functions/openai-proxy', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                imageBase64: pngBase64, // PNG ë³€í™˜ëœ ë°ì´í„°
                prompt: optimizedPrompt
            })
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`gpt-image-1 í”„ë¡ì‹œ ì˜¤ë¥˜: ${response.status} - ${errorText}`);
        }

        const data = await response.json();
        
        console.log('gpt-image-1 ì‘ë‹µ ë¶„ì„:', {
            hasData: !!data.data,
            model: data.model || 'unknown',
            processingMethod: data.processing_method || 'standard',
            verification: data.verification || 'none'
        });
        
        if (data.data && data.data[0] && data.data[0].b64_json) {
            console.log('âœ… gpt-image-1 ë³€í™˜ ì™„ë£Œ');
            
            // 6. ì¢…íš¡ë¹„ ë³´ì • (gpt-image-1 ê²°ê³¼ë¥¼ ì›ë³¸ ë¹„ìœ¨ë¡œ)
            const correctedBase64 = await correctAspectRatio(
                data.data[0].b64_json,
                originalDimensions.width,
                originalDimensions.height
            );
            
            console.log('ğŸ¨ ì¢…íš¡ë¹„ ë³´ì • ì™„ë£Œ');
            
            return {
                base64: correctedBase64,
                mimeType: 'image/png',
                url: `data:image/png;base64,${correctedBase64}`
            };
        } else {
            throw new Error('gpt-image-1 ì‘ë‹µì— ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ');
        }
        
    } catch (error) {
        console.error('âŒ gpt-image-1 ë³€í™˜ ì‹¤íŒ¨:', error);
        throw error;
    }
};

/**
 * ğŸš€ ì—…ë°ì´íŠ¸ëœ í•˜ì´ë¸Œë¦¬ë“œ ë³€í™˜ (gpt-image-1 + Gemini)
 */
export const hybridFaceTransformation = async (
  originalImage: ImageFile,
  facePrompt: string,
  clothingPrompt: string
): Promise<ImageFile | null> => {
  try {
    console.log('ğŸš€ gpt-image-1 + Gemini í•˜ì´ë¸Œë¦¬ë“œ ë³€í™˜ ì‹œì‘!');
    console.log('- Face prompt:', facePrompt);
    console.log('- Clothing prompt:', clothingPrompt || 'None');
    
    // Step 1: ì§„ì§œ gpt-image-1ìœ¼ë¡œ ì–¼êµ´ ë³€í™˜ (ë¦¬ì‚¬ì´ì¦ˆ + PNG ë³€í™˜ + ì¢…íš¡ë¹„ ë³´ì • í¬í•¨)
    console.log('Step 1: gpt-image-1 ì–¼êµ´ ë³€í™˜ (GPT-4V + DALL-E-3 + ì¢…íš¡ë¹„ ë³´ì •)');
    
    const faceChangedImage = await transformFaceWithGPTImage1(
      originalImage, 
      facePrompt
    );
    
    if (!faceChangedImage) {
      throw new Error('Step 1 ì‹¤íŒ¨: gpt-image-1 ì–¼êµ´ ë³€í™˜ ì‹¤íŒ¨');
    }
    
    console.log('âœ… Step 1 ì™„ë£Œ: gpt-image-1 ì–¼êµ´ ë³€í™˜ + ì¢…íš¡ë¹„ ë³´ì •');
    
    // ì˜ìƒ ë³€ê²½ì´ ì—†ìœ¼ë©´ 1ë‹¨ê³„ ê²°ê³¼ë§Œ ë°˜í™˜
    if (!clothingPrompt || clothingPrompt.trim() === '') {
      console.log('ë³€í™˜ ì™„ë£Œ (ì–¼êµ´ë§Œ)');
      return faceChangedImage;
    }
    
    // Step 2: Geminië¡œ ì˜ìƒ ë³€í™˜
    console.log('Step 2: Gemini ì˜ìƒ ë³€í™˜');
    
    const finalResult = await changeClothingOnly(faceChangedImage, clothingPrompt);
    
    if (!finalResult) {
      console.warn('Step 2 ì‹¤íŒ¨, Step 1 ê²°ê³¼ ë°˜í™˜');
      return faceChangedImage;
    }
    
    console.log('âœ… Step 2 ì™„ë£Œ: ì˜ìƒ ë³€í™˜');
    console.log('ğŸ‰ gpt-image-1 + Gemini í•˜ì´ë¸Œë¦¬ë“œ ë³€í™˜ ì™„ë£Œ!');
    
    return finalResult;
    
  } catch (error) {
    console.error('âŒ í•˜ì´ë¸Œë¦¬ë“œ ë³€í™˜ ì‹¤íŒ¨:', error);
    
    if (error instanceof Error) {
      const errorMessage = error.message;
      
      if (errorMessage.includes('Step 1')) {
        throw new Error(`gpt-image-1 ì–¼êµ´ ë³€í™˜ ì‹¤íŒ¨: ${errorMessage}`);
      } else if (errorMessage.includes('gpt-image-1 í”„ë¡ì‹œ')) {
        throw new Error(`gpt-image-1 API ì˜¤ë¥˜: ${errorMessage}`);
      }
      
      throw error;
    }
    
    throw new Error("gpt-image-1 í•˜ì´ë¸Œë¦¬ë“œ ì–¼êµ´ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
  }
};

/**
 * ğŸ”„ ìŠ¤ë§ˆíŠ¸ ë³€í™˜ (gpt-image-1 ì‹¤íŒ¨ì‹œ Gemini í´ë°±)
 */
export const smartFaceTransformation = async (
  originalImage: ImageFile,
  facePrompt: string,
  clothingPrompt: string
): Promise<{ result: ImageFile | null; method: string }> => {
  try {
    // ë¨¼ì € gpt-image-1 + Gemini í•˜ì´ë¸Œë¦¬ë“œ ì‹œë„
    const hybridResult = await hybridFaceTransformation(
      originalImage, 
      facePrompt, 
      clothingPrompt
    );
    
    return { 
      result: hybridResult, 
      method: 'gpt-image-1 (GPT-4V + DALL-E-3 + ì¢…íš¡ë¹„ë³´ì •) + Gemini í•˜ì´ë¸Œë¦¬ë“œ' 
    };
    
  } catch (error) {
    console.log('gpt-image-1 í•˜ì´ë¸Œë¦¬ë“œ ì‹¤íŒ¨, Gemini ì „ìš©ìœ¼ë¡œ í´ë°±...');
    console.error('ì˜¤ë¥˜:', error);
    
    try {
      // gpt-image-1 ì‹¤íŒ¨ì‹œ ê¸°ì¡´ Gemini ë°©ì‹ìœ¼ë¡œ í´ë°±
      const geminiResult = await changeFaceInImage(
        originalImage, 
        facePrompt,
        clothingPrompt
      );
      
      return { 
        result: geminiResult, 
        method: 'Gemini Only (gpt-image-1 í´ë°±)' 
      };
      
    } catch (fallbackError) {
      console.error('ëª¨ë“  ë³€í™˜ ë°©ë²• ì‹¤íŒ¨');
      throw new Error(`ëª¨ë“  ë³€í™˜ ì‹¤íŒ¨: ${fallbackError instanceof Error ? fallbackError.message : 'Unknown error'}`);
    }
  }
};

/**
 * ğŸ“Š ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
 */
export const getHybridServiceStatus = () => {
  return {
    version: '3.0',
    method: 'gpt-image-1 ì™„ì „ êµ¬í˜„',
    step1: 'gpt-image-1 (GPT-4V ë¶„ì„ + DALL-E-3 í™•ì‚° ì¬êµ¬ì„±)',
    step2: 'Gemini ì˜ìƒ ë³€í™˜',
    fallback: 'Gemini Only',
    features: [
      'gpt-image-1 ë¦¬ì‚¬ì´ì¦ˆ ìµœì í™” (768~1536px)',
      'PNG ë³€í™˜ (OpenAI í˜¸í™˜ì„±)',
      'GPT-4V ì´ë¯¸ì§€ ë¶„ì„ (512ì°¨ì› embedding)',
      'DALL-E-3 í™•ì‚° ê¸°ë°˜ ì¬êµ¬ì„±',
      'ì¢…íš¡ë¹„ ìë™ ë³´ì • (ì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€)',
      'í—¤ì–´/ë°°ê²½ ë³´ì¡´ (0.95 ê°€ì¤‘ì¹˜)',
      'Gemini ì˜ìƒ ë³€í™˜ ì—°ê³„',
      'ìŠ¤ë§ˆíŠ¸ í´ë°± ì‹œìŠ¤í…œ'
    ]
  };
};
