// services/geminiService.ts
import { GoogleGenAI, Modality } from "@google/genai";
import { ImageProcessor } from '../utils/imageProcessor';
import type { ImageFile } from '../types';

// í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
const apiKey = process.env.GEMINI_API_KEY;

if (!apiKey) {
    throw new Error("GEMINI_API_KEY environment variable is not set.");
}

const ai = new GoogleGenAI({ apiKey });

// ğŸ›ï¸ ê¸°ëŠ¥ í”Œë˜ê·¸ (ë°°í¬ ì•ˆì „ì„±ì„ ìœ„í•œ ì ì§„ì  í™œì„±í™”)
const FEATURE_FLAGS = {
    // ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‹ ê¸°ëŠ¥ í™œì„±í™”, ë°°í¬ ì‹œ falseë¡œ ì„¤ì •
    ENABLE_IMPROVED_PROMPTS: process.env.NODE_ENV === 'development' || process.env.ENABLE_IMPROVED_FACE === 'true',
    ENABLE_HAIR_ANALYSIS: process.env.ENABLE_HAIR_ANALYSIS === 'true',
    ENABLE_STEP_VERIFICATION: process.env.ENABLE_VERIFICATION === 'true',
    // ì‚¬ìš©ì ë¹„ìœ¨ ì œì–´ (0-100)
    IMPROVED_USER_PERCENTAGE: parseInt(process.env.IMPROVED_USER_PERCENTAGE || '0')
};

console.log('ğŸ›ï¸ Feature flags loaded:', {
    improved: FEATURE_FLAGS.ENABLE_IMPROVED_PROMPTS,
    analysis: FEATURE_FLAGS.ENABLE_HAIR_ANALYSIS,
    verification: FEATURE_FLAGS.ENABLE_STEP_VERIFICATION,
    userPercentage: FEATURE_FLAGS.IMPROVED_USER_PERCENTAGE
});

// ğŸ”’ í—¤ì–´ ë³´ì¡´ ê°•í™” ë¬¸êµ¬ (ì•ˆì „í•œ ì¶”ê°€ ë³´í˜¸)
const getHairProtectionBooster = (): string => {
    return `

ğŸ”’ CRITICAL HAIR PRESERVATION PROTOCOL:
- Maintain the hair's ORIGINAL NATURAL TEXTURE exactly as shown
- Do NOT add artificial curls, waves, or extra volume that wasn't there originally
- Keep the hair's natural roughness and organic, unstyled appearance
- Preserve the exact hair direction, fall pattern, and styling
- Hair color, length, and cut must remain completely unchanged
- The hair should look identical to the source image in every aspect`;
};

// ğŸ“Š ì‚¬ìš©ìë³„ ê¸°ëŠ¥ í™œì„±í™” ì²´í¬ (A/B í…ŒìŠ¤íŠ¸ìš©)
const shouldUseImprovedFeatures = (): boolean => {
    if (FEATURE_FLAGS.IMPROVED_USER_PERCENTAGE === 0) return false;
    if (FEATURE_FLAGS.IMPROVED_USER_PERCENTAGE >= 100) return true;
    
    // ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ì‚¬ìš©ì ë¶„í•  (ì‹¤ì œë¡œëŠ” userId ê¸°ë°˜ìœ¼ë¡œ í•  ìˆ˜ ìˆìŒ)
    const randomSeed = Math.floor(Math.random() * 100);
    return randomSeed < FEATURE_FLAGS.IMPROVED_USER_PERCENTAGE;
};

// ğŸ¯ 1ë‹¨ê³„: ì–¼êµ´ ë³€í˜• ì „ìš© í”„ë¡¬í”„íŠ¸ (ê°œì„  ë²„ì „)
const getFaceOnlyPromptImproved = (facePrompt: string): string => {
  const hairBooster = getHairProtectionBooster();
  
  // 10ëŒ€ ë‚¨ì„±
  if (facePrompt.includes('late teens') && facePrompt.includes('male')) {
    return `
You are a master portrait editor specializing in facial feature adjustment with ABSOLUTE HAIR PRESERVATION technology.

Transform this person to appear as a different 17-19 year old East Asian male while maintaining their core facial identity.

${hairBooster}

FACIAL TRANSFORMATION APPROACH:
- MAINTAIN the person's basic bone structure and facial foundation
- ADJUST facial features to create a teenage male appearance:
  * Soften jawline and create more youthful proportions
  * Adjust eye shape and brightness for teenage energy
  * Smooth skin texture with natural teenage glow
  * Modify facial expression to show youthful confidence
  * Adjust eyebrow shape for natural teenage fullness
- CREATE the impression of a different person through feature adjustments
- PRESERVE the core facial identity while transforming the appearance

CLOTHING PRESERVATION:
- Keep original clothing exactly unchanged
- Preserve all clothing details, colors, and patterns

TECHNICAL PRECISION:
- Match original lighting and shadows perfectly
- Maintain photorealistic quality with teenage skin characteristics
- Preserve background and pose exactly

Result: The same person transformed to appear as a different teenage male through careful feature adjustments.`;
  }
  
  // 20ëŒ€ ë‚¨ì„±
  if (facePrompt.includes('early 20s') && facePrompt.includes('male')) {
    return `
You are an expert facial feature modifier with ADVANCED HAIR PROTECTION SYSTEM.

Transform this person's appearance to look like a different 22-25 year old East Asian male while preserving their fundamental facial structure.

${hairBooster}

FACIAL FEATURE ADJUSTMENT:
- KEEP the person's basic facial bone structure intact
- MODIFY features to create a young adult male appearance:
  * Adjust jawline definition for masculine maturity
  * Refine eye shape with confident, bright expression
  * Enhance skin quality with healthy young adult texture
  * Modify facial proportions for 20s male characteristics
  * Adjust eyebrow shape for masculine definition
- TRANSFORM the overall appearance while maintaining core identity
- CREATE the effect of a different person through strategic adjustments

CLOTHING PRESERVATION:
- Original clothing must remain exactly as shown
- Preserve all clothing elements without modification

TECHNICAL REQUIREMENTS:
- Perfect lighting and shadow matching
- Photorealistic young adult male skin
- Preserve background and pose exactly

Result: The same person appearing as a different young adult male through facial adjustments.`;
  }
  
  // ë‹¤ë¥¸ ì—°ë ¹ëŒ€ë„ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ê³„ì†...
  // (ë‚˜ë¨¸ì§€ ì—°ë ¹ëŒ€ í”„ë¡¬í”„íŠ¸ë„ hairBooster ì¶”ê°€)
  
  // ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ìŠ¤íƒ€ì¼ ì˜µì…˜ë“¤)
  return `
You are a master facial feature transformer with ULTIMATE HAIR PRESERVATION TECHNOLOGY.

Transform this person's appearance based on the following style while maintaining their core facial identity.

${hairBooster}

STYLE TRANSFORMATION:
Transform based on: ${facePrompt}
- PRESERVE the person's fundamental facial structure and bone architecture
- MODIFY features to create the requested style/appearance:
  * Adjust facial contours and proportions appropriately
  * Enhance or modify expression and facial characteristics
  * Refine skin texture and quality for the desired look
  * Modify facial features while maintaining core identity
- MAINTAIN the person's basic facial foundation while transforming appearance
- CREATE the impression of a different person through strategic feature adjustments

CLOTHING PRESERVATION:
- Original clothing must remain exactly unchanged
- Preserve all clothing details and styling

TECHNICAL MASTERY:
- Match original lighting and shadows perfectly
- Maintain photorealistic quality appropriate for transformation
- Preserve background and pose exactly

Result: The same person transformed to appear different through strategic facial feature modifications while preserving their core identity.`;
};

// ğŸ“ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ (ì•ˆì „ ë²„ì „ - ìµœì†Œ ê°œì„ )
const getFaceOnlyPromptSafe = (facePrompt: string): string => {
  // ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì— í—¤ì–´ ë³´í˜¸ë§Œ ê°•í™”
  const basePrompt = getFaceOnlyPromptOriginal(facePrompt);
  const minimalHairProtection = `

ğŸ”’ ENHANCED HAIR PROTECTION:
Keep the hair texture natural and unmodified - do not make it more curly, wavy, or voluminous than the original. Maintain the exact natural hair appearance.`;
  
  return basePrompt + minimalHairProtection;
};

// ğŸ”„ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ (ì™„ì „ ë°±ì—…)
const getFaceOnlyPromptOriginal = (facePrompt: string): string => {
  // ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ë³´ì¡´
  if (facePrompt.includes('late teens') && facePrompt.includes('male')) {
    return `
You are a master portrait editor specializing in facial feature adjustment. Transform this person to appear as a different 17-19 year old East Asian male while maintaining their core facial identity.

HAIR PRESERVATION (ABSOLUTE PRIORITY):
- Study the exact hairstyle: color, texture, length, style, parting, volume, positioning
- Keep hair 100% IDENTICAL - no changes to any hair characteristics
- Preserve every strand position and natural flow

FACIAL TRANSFORMATION APPROACH:
- MAINTAIN the person's basic bone structure and facial foundation
- ADJUST facial features to create a teenage male appearance:
  * Soften jawline and create more youthful proportions
  * Adjust eye shape and brightness for teenage energy
  * Smooth skin texture with natural teenage glow
  * Modify facial expression to show youthful confidence
  * Adjust eyebrow shape for natural teenage fullness
- CREATE the impression of a different person through feature adjustments
- PRESERVE the core facial identity while transforming the appearance

CLOTHING PRESERVATION:
- Keep original clothing exactly unchanged
- Preserve all clothing details, colors, and patterns

TECHNICAL PRECISION:
- Match original lighting and shadows perfectly
- Maintain photorealistic quality with teenage skin characteristics
- Preserve background and pose exactly

Result: The same person transformed to appear as a different teenage male through careful feature adjustments.`;
  }
  
  // ë‚˜ë¨¸ì§€ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ë“¤...
  return `ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©`;
};

// 2ë‹¨ê³„: ì˜ìƒ ë³€í™˜ ì „ìš© í”„ë¡¬í”„íŠ¸ (ì•ˆì „í•˜ê²Œ ìœ ì§€)
const getClothingOnlyPrompt = (clothingPrompt: string): string => {
  return `
You are a CLOTHING TRANSFORMATION specialist with ABSOLUTE FACE AND HAIR PROTECTION technology.

CRITICAL PRESERVATION REQUIREMENTS:
- The person's FACE must remain EXACTLY as shown - DO NOT change any facial features
- The person's HAIR must remain EXACTLY as shown - DO NOT change any hair details
- Keep identical: facial structure, skin, eyes, nose, mouth, expressions, hair color, hair texture, hair style, hair positioning

ğŸ”’ ENHANCED HAIR PROTECTION:
- Hair texture must remain completely natural and unchanged
- Do not add any styling, curls, waves, or volume modifications
- Preserve the exact hair appearance from the input image

CLOTHING TRANSFORMATION ONLY:
Transform the clothing to: ${clothingPrompt}
- Change ONLY the clothing, keeping the fit and style appropriate for the person
- Ensure the new clothing looks natural and well-fitted
- Maintain the same pose and body position

TECHNICAL PRECISION:
- Match original lighting and shadows perfectly
- Keep the same background
- Preserve all non-clothing elements exactly
- Maintain photorealistic quality

Result: Same person with identical face and hair, but wearing the new clothing style.`;
};

// ğŸ¯ 1ë‹¨ê³„: ì–¼êµ´ë§Œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
const changeFaceOnly = async (
    originalImage: ImageFile, 
    facePrompt: string
): Promise<ImageFile | null> => {
    try {
        console.log('ğŸ¯ Starting face-only transformation...');
        
        // ì‚¬ìš©ìë³„ ê¸°ëŠ¥ ì„ íƒ
        const useImproved = FEATURE_FLAGS.ENABLE_IMPROVED_PROMPTS && shouldUseImprovedFeatures();
        console.log(`ğŸ“Š Using ${useImproved ? 'improved' : 'safe'} prompts for this user`);
        
        let prompt: string;
        
        if (useImproved) {
            prompt = getFaceOnlyPromptImproved(facePrompt);
        } else if (FEATURE_FLAGS.ENABLE_IMPROVED_PROMPTS) {
            prompt = getFaceOnlyPromptSafe(facePrompt);
        } else {
            prompt = getFaceOnlyPromptOriginal(facePrompt);
        }

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: {
                parts: [
                    {
                        inlineData: {
                            data: originalImage.base64,
                            mimeType: originalImage.mimeType,
                        },
                    },
                    {
                        text: prompt,
                    },
                ],
            },
            config: {
                responseModalities: [Modality.IMAGE, Modality.TEXT],
                temperature: 0.3, // ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í–¥ìƒ
            },
        });
        
        for (const part of response.candidates[0].content.parts) {
            if (part.inlineData) {
                const originalBase64 = part.inlineData.data;
                const originalMimeType = part.inlineData.mimeType;
                
                try {
                    const cleanedImage = await ImageProcessor.cleanBase64Image(
                        originalBase64, 
                        originalMimeType
                    );
                    console.log('âœ… Face transformation completed successfully');
                    return cleanedImage;
                } catch (cleanError) {
                    console.warn('âš ï¸ Failed to clean metadata, returning original:', cleanError);
                    return {
                        base64: originalBase64,
                        mimeType: originalMimeType,
                        url: `data:${originalMimeType};base64,${originalBase64}`
                    };
                }
            }
        }
        
        console.warn('âš ï¸ No image data received from Gemini API');
        return null;

    } catch (error) {
        console.error("âŒ Error in face-only transformation:", error);
        
        // ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
        if (FEATURE_FLAGS.ENABLE_IMPROVED_PROMPTS) {
            console.log('ğŸ”„ Retrying with original prompt...');
            try {
                const fallbackPrompt = getFaceOnlyPromptOriginal(facePrompt);
                const response = await ai.models.generateContent({
                    model: 'gemini-2.5-flash-image-preview',
                    contents: {
                        parts: [
                            {
                                inlineData: {
                                    data: originalImage.base64,
                                    mimeType: originalImage.mimeType,
                                },
                            },
                            {
                                text: fallbackPrompt,
                            },
                        ],
                    },
                    config: {
                        responseModalities: [Modality.IMAGE, Modality.TEXT],
                    },
                });
                
                for (const part of response.candidates[0].content.parts) {
                    if (part.inlineData) {
                        console.log('âœ… Fallback transformation successful');
                        return {
                            base64: part.inlineData.data,
                            mimeType: part.inlineData.mimeType,
                            url: `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`
                        };
                    }
                }
            } catch (fallbackError) {
                console.error("âŒ Fallback also failed:", fallbackError);
            }
        }
        
        throw new Error("Failed to change face using Gemini API.");
    }
};

// ğŸ½ 2ë‹¨ê³„: ì˜ìƒë§Œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ì•ˆì „ì„± ê°•í™”)
const changeClothingOnly = async (
    faceChangedImage: ImageFile, 
    clothingPrompt: string
): Promise<ImageFile | null> => {
    try {
        console.log('ğŸ‘• Starting clothing-only transformation...');
        
        const prompt = getClothingOnlyPrompt(clothingPrompt);

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: {
                parts: [
                    {
                        inlineData: {
                            data: faceChangedImage.base64,
                            mimeType: faceChangedImage.mimeType,
                        },
                    },
                    {
                        text: prompt,
                    },
                ],
            },
            config: {
                responseModalities: [Modality.IMAGE, Modality.TEXT],
                temperature: 0.3,
            },
        });
        
        for (const part of response.candidates[0].content.parts) {
            if (part.inlineData) {
                const originalBase64 = part.inlineData.data;
                const originalMimeType = part.inlineData.mimeType;
                
                try {
                    const cleanedImage = await ImageProcessor.cleanBase64Image(
                        originalBase64, 
                        originalMimeType
                    );
                    console.log('âœ… Clothing transformation completed successfully');
                    return cleanedImage;
                } catch (cleanError) {
                    console.warn('âš ï¸ Failed to clean metadata, returning original:', cleanError);
                    return {
                        base64: originalBase64,
                        mimeType: originalMimeType,
                        url: `data:${originalMimeType};base64,${originalBase64}`
                    };
                }
            }
        }
        
        console.warn('âš ï¸ No image data received for clothing transformation');
        return null;

    } catch (error) {
        console.error("âŒ Error in clothing transformation:", error);
        throw new Error("Failed to change clothing using Gemini API.");
    }
};

// ğŸ›¡ï¸ ë©”ì¸ í•¨ìˆ˜: ì•ˆì „í•œ 2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤
export const changeFaceInImage = async (
    originalImage: ImageFile, 
    facePrompt: string,
    clothingPrompt: string
): Promise<ImageFile | null> => {
    try {
        console.log('ğŸš€ Starting safe 2-step transformation process...');
        console.log('ğŸ›ï¸ Feature flags:', FEATURE_FLAGS);
        console.log('ğŸ’¡ User charged: 1 credit | Backend process: Enhanced quality service');
        
        // 1ë‹¨ê³„: ì–¼êµ´ë§Œ ë³€í™˜ (í•„ìˆ˜)
        console.log('ğŸ“ Step 1: Face transformation (required)...');
        const faceChangedImage = await changeFaceOnly(originalImage, facePrompt);
        
        if (!faceChangedImage) {
            throw new Error("Face transformation failed in step 1");
        }
        
        console.log('âœ… Step 1 completed successfully');
        
        // ì˜ìƒ ë³€ê²½ì´ ì—†ìœ¼ë©´ 1ë‹¨ê³„ ê²°ê³¼ ë°˜í™˜
        if (!clothingPrompt || clothingPrompt.trim() === '') {
            console.log('ğŸ“‹ No clothing change requested - returning step 1 result');
            console.log('ğŸ’° Credit usage: 1 credit (face transformation only)');
            return faceChangedImage;
        }
        
        // 2ë‹¨ê³„: ì˜ìƒ ë³€í™˜ (ì„ íƒì  - ì‹¤íŒ¨í•´ë„ 1ë‹¨ê³„ ê²°ê³¼ëŠ” ë³´ì¥)
        console.log('ğŸ“ Step 2: Clothing transformation (enhancement service)...');
        try {
            const finalImage = await changeClothingOnly(faceChangedImage, clothingPrompt);
            
            if (finalImage) {
                console.log('âœ… Step 2 completed successfully');
                console.log('ğŸ’° Credit usage: 1 credit (both steps successful - premium quality service)');
                return finalImage;
            } else {
                console.log('âš ï¸ Step 2 returned null - using step 1 result');
                console.log('ğŸ’° Credit usage: 1 credit (step 1 successful, step 2 incomplete)');
                return faceChangedImage;
            }
            
        } catch (step2Error) {
            console.warn('âš ï¸ Step 2 failed, but step 1 succeeded - returning partial result:', step2Error);
            console.log('ğŸ’° Credit usage: 1 credit (step 1 successful, step 2 failed)');
            return faceChangedImage; // 2ë‹¨ê³„ ì‹¤íŒ¨í•´ë„ 1ë‹¨ê³„ ê²°ê³¼ëŠ” ì œê³µ
        }

    } catch (error) {
        console.error("âŒ Critical error in transformation process:", error);
        
        // ìµœí›„ì˜ ì•ˆì „ì¥ì¹˜: ì™„ì „ ì‹¤íŒ¨ ì‹œì—ë„ ì‚¬ìš©ìì—ê²Œ ì˜ë¯¸ìˆëŠ” ì—ëŸ¬ ë©”ì‹œì§€
        if (error instanceof Error) {
            throw new Error(`ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`);
        } else {
            throw new Error("ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì´ë¯¸ì§€ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
        }
    }
};

// ğŸ”§ ê°œë°œì ë„êµ¬: ê¸°ëŠ¥ í”Œë˜ê·¸ ìƒíƒœ í™•ì¸
export const getFeatureStatus = () => {
    return {
        flags: FEATURE_FLAGS,
        environment: process.env.NODE_ENV,
        userWillUseImproved: shouldUseImprovedFeatures()
    };
};

// ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ìš© (ì„ íƒì )
export const logTransformationMetrics = (
    step: string, 
    success: boolean, 
    duration: number, 
    userId?: string
) => {
    const metrics = {
        timestamp: new Date().toISOString(),
        step,
        success,
        duration,
        userId,
        flags: FEATURE_FLAGS
    };
    
    console.log('ğŸ“Š Transformation metrics:', metrics);
    
    // ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” analytics ì„œë¹„ìŠ¤ë¡œ ì „ì†¡
    // analytics.track('face_transformation', metrics);
};
