// netlify/functions/openai-proxy.js - ì§„ì§œ gpt-image-1 Edit API

exports.config = { timeout: 26 };

exports.handler = async (event, context) => {
  console.log('[OpenAI Proxy] ğŸ¯ REAL gpt-image-1 Edit API');
  
  const corsHeaders = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type',
    'Access-Control-Allow-Methods': 'POST, OPTIONS'
  };
  
  if (event.httpMethod === 'OPTIONS') {
    return { statusCode: 200, headers: corsHeaders, body: '' };
  }

  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return {
      statusCode: 500,
      headers: corsHeaders,
      body: JSON.stringify({ error: 'OpenAI API key not configured' })
    };
  }

  try {
    const { imageBase64, prompt } = JSON.parse(event.body);
    
    console.log('[gpt-image-1] ğŸš€ ì§„ì§œ gpt-image-1 Edit API ì‹œì‘:', {
      hasImage: !!imageBase64,
      imageSize: Math.round(imageBase64?.length / 1024) + 'KB',
      promptLength: prompt?.length
    });

    // gpt-image-1 ì „ìš© 32,000ì ê·¹ëŒ€í™” í”„ë¡¬í”„íŠ¸
    const gptImage1Prompt = `
EXTREME FACIAL TRANSFORMATION USING gpt-image-1:

PRIMARY OBJECTIVE: ${prompt}

TRANSFORMATION REQUIREMENTS:
- COMPLETELY OBLITERATE original facial features
- REPLACE with entirely different face as specified
- MAXIMUM transformation intensity
- ZERO resemblance to original person
- Make changes DRAMATIC and OBVIOUS

DETAILED FACIAL CHANGES:
- Face shape: Complete geometric reconstruction
- Eye area: Different size, shape, spacing, and expression
- Nose structure: Entirely different bridge height, width, and tip shape
- Mouth features: Different lip thickness, shape, and smile pattern
- Cheekbone structure: Completely different prominence and angle
- Jawline: New bone structure and definition
- Skin characteristics: Different texture, tone, and aging pattern
- Eyebrow features: Different thickness, arch, and positioning

PRESERVATION RULES:
- Hair: Maintain 100% identical style, color, length, and texture
- Background: Preserve all environmental elements perfectly
- Clothing: Keep all garments and accessories unchanged
- Body pose: Maintain exact positioning and angle
- Lighting: Preserve original light sources and shadows
- Composition: Keep framing and perspective identical

TECHNICAL SPECIFICATIONS:
- Generate photorealistic skin with natural imperfections
- Ensure seamless integration between new face and preserved elements
- Apply professional portrait lighting consistency
- Maintain high resolution and sharp details
- Create natural facial proportions and symmetry

QUALITY ASSURANCE:
- The transformation should be immediately recognizable as a different person
- Facial features should look naturally born, not artificially imposed
- All preserved elements should remain pixel-perfect
- The result should appear as a professionally shot portrait

Execute this facial transformation with maximum fidelity to the specifications while preserving all non-facial elements exactly as they appear in the source image.
    `.trim();

    console.log('[gpt-image-1] ğŸ“ ê·¹ëŒ€í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±:', gptImage1Prompt.length, 'ì (32K í•œë„)');

    const imageBuffer = Buffer.from(imageBase64, 'base64');
    const boundary = '----gpt-image-1-edit-' + Math.random().toString(36).substring(2, 15);
    const formData = createGPTImage1FormData(boundary, imageBase64, gptImage1Prompt);
    
    const startTime = Date.now();
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 23000);
    
    try {
      // ğŸ”¥ ì§„ì§œ gpt-image-1 Edit API í˜¸ì¶œ
      const response = await fetch('https://api.openai.com/v1/images/edits', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': `multipart/form-data; boundary=${boundary}`
        },
        body: formData,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      const responseTime = Date.now() - startTime;
      
      console.log('[gpt-image-1] âš¡ API ì‘ë‹µ:', {
        status: response.status,
        responseTime: responseTime + 'ms',
        remaining: context.getRemainingTimeInMillis()
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('[gpt-image-1] âŒ API ì˜¤ë¥˜:', {
          status: response.status,
          error: errorText.substring(0, 200)
        });
        
        return {
          statusCode: response.status,
          headers: corsHeaders,
          body: JSON.stringify({ 
            error: `gpt-image-1 API Error: ${response.status}`,
            details: errorText.substring(0, 100),
            useGeminiFallback: true
          })
        };
      }

      const data = await response.json();
      
      // gpt-image-1ì€ í•­ìƒ base64ë¥¼ ë°˜í™˜
      console.log('[gpt-image-1] ğŸ”¬ ê²°ê³¼ ë¶„ì„:', {
        hasData: !!data.data,
        dataLength: data.data?.length || 0,
        hasB64Json: !!(data.data?.[0]?.b64_json),
        b64Length: data.data?.[0]?.b64_json?.length || 0,
        model: data.model || 'unknown'
      });
      
      // ë³€í™˜ ê²€ì¦
      if (data.data && data.data[0] && data.data[0].b64_json) {
        const resultBase64 = data.data[0].b64_json;
        const originalSize = imageBase64.length;
        const resultSize = resultBase64.length;
        const sizeDiff = Math.abs(resultSize - originalSize);
        const changePercent = ((sizeDiff / originalSize) * 100).toFixed(1);
        
        console.log('[gpt-image-1] ğŸ“Š ë³€í™˜ ê²€ì¦:', {
          originalSize: Math.round(originalSize / 1024) + 'KB',
          resultSize: Math.round(resultSize / 1024) + 'KB',
          changePercent: changePercent + '%',
          likely_transformed: sizeDiff > 1000 ? 'âœ… ë³€í™˜ë¨' : 'âš ï¸ ë¯¸ë¯¸í•œ ë³€í™”',
          totalTime: responseTime + 'ms'
        });
      }
      
      console.log('[gpt-image-1] âœ… gpt-image-1 Edit ì™„ë£Œ - ì´ ì†Œìš”ì‹œê°„:', responseTime + 'ms');
      
      return {
        statusCode: 200,
        headers: corsHeaders,
        body: JSON.stringify({
          ...data,
          processing_method: 'gpt-image-1_Edit_API',
          response_time: responseTime + 'ms'
        })
      };
      
    } catch (fetchError) {
      clearTimeout(timeoutId);
      
      if (fetchError.name === 'AbortError') {
        console.log('[gpt-image-1] â° 23ì´ˆ íƒ€ì„ì•„ì›ƒ');
        return {
          statusCode: 408,
          headers: corsHeaders,
          body: JSON.stringify({ 
            error: 'TIMEOUT',
            message: 'gpt-image-1 request timeout after 23 seconds',
            useGeminiFallback: true
          })
        };
      }
      
      throw fetchError;
    }
    
  } catch (error) {
    console.error('[gpt-image-1] ğŸ’¥ ì¹˜ëª…ì  ì˜¤ë¥˜:', error.message);
    
    return {
      statusCode: 500,
      headers: corsHeaders,
      body: JSON.stringify({ 
        error: error.message,
        useGeminiFallback: true
      })
    };
  }
};

// ğŸ”§ gpt-image-1 ì „ìš© FormData ìƒì„±
function createGPTImage1FormData(boundary, imageBase64, prompt) {
  const imageBuffer = Buffer.from(imageBase64, 'base64');
  
  const formParts = [];
  
  // ğŸ¯ gpt-image-1 ëª¨ë¸ ëª…ì‹œ
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="model"');
  formParts.push('');
  formParts.push('gpt-image-1');
  
  // 32K ê·¹ëŒ€í™” í”„ë¡¬í”„íŠ¸
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="prompt"');
  formParts.push('');
  formParts.push(prompt);
  
  // ğŸ†• gpt-image-1 ì „ìš© íŒŒë¼ë¯¸í„°ë“¤
  
  // input_fidelity: high (ì–¼êµ´ íŠ¹ì§• ë§¤ì¹­ ê°•í™”)
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="input_fidelity"');
  formParts.push('');
  formParts.push('high');
  
  // size: auto (ìë™ ì¢…íš¡ë¹„)
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="size"');
  formParts.push('');
  formParts.push('auto');
  
  // quality: high
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="quality"');
  formParts.push('');
  formParts.push('high');
  
  // output_format: png (ê¸°ë³¸ê°’ì´ì§€ë§Œ ëª…ì‹œ)
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="output_format"');
  formParts.push('');
  formParts.push('png');
  
  // n: 1ê°œ ìƒì„±
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="n"');
  formParts.push('');
  formParts.push('1');
  
  // ì´ë¯¸ì§€ íŒŒì¼
  formParts.push(`--${boundary}`);
  formParts.push('Content-Disposition: form-data; name="image"; filename="face_transform.png"');
  formParts.push('Content-Type: image/png');
  formParts.push('');
  
  // ì „ì²´ ì¡°í•©
  const textPart = formParts.join('\r\n') + '\r\n';
  const closingBoundary = `\r\n--${boundary}--\r\n`;
  
  return Buffer.concat([
    Buffer.from(textPart, 'utf8'),
    imageBuffer,
    Buffer.from(closingBoundary, 'utf8')
  ]);
}
